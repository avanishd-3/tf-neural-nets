{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlvCPi1vqvHm"
      },
      "source": [
        "# Improved Fashion MNIST accuracy using CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRc15coo4h6B",
        "outputId": "94d593a8-571c-43d9-eb94-1b84c8c0b48b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "%pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gs0c7l6lqpjq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras_tuner as kt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-ohd0sfq59O"
      },
      "source": [
        "## Load Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_vadPIiq8QL",
        "outputId": "3fa6fa3c-d3b3-439f-da75-5fa363859d86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist\n",
        "\n",
        "# Scale pixel intensities (immediate 10x improvement to accuracy)\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NTO-tTrreMq"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O5wYkmyhrd6P"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    DefaultConv2D = partial(tf.keras.layers.Conv2D,\n",
        "                           padding=\"same\",\n",
        "                           activation='relu',\n",
        "                           kernel_initializer='he_normal')\n",
        "\n",
        "\n",
        "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
        "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\", \"nadam\"])\n",
        "\n",
        "    if optimizer == 'adam':\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    elif optimizer == 'nadam':\n",
        "        optimizer = tf.keras.optimizers.Nadam(learning_rate=learning_rate)\n",
        "    else:\n",
        "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Initial convolutional layer\n",
        "    model.add(DefaultConv2D(\n",
        "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=32),\n",
        "        kernel_size=hp.Choice('conv_1_kernel', values=[3, 5, 7]),\n",
        "        input_shape=[28, 28, 1]))\n",
        "\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "    # Second convolutional block\n",
        "    model.add(DefaultConv2D(\n",
        "        filters=hp.Int('conv_2_filter', min_value=64, max_value=256, step=64),\n",
        "        kernel_size=hp.Choice('conv_2_kernel', values=[3, 5])))\n",
        "\n",
        "    # Optional second layer in the block\n",
        "    if hp.Boolean('conv_2_second_layer'):\n",
        "        model.add(DefaultConv2D(\n",
        "            filters=hp.Int('conv_2_second_filter', min_value=64, max_value=256, step=64),\n",
        "            kernel_size=3))\n",
        "\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "    # Third convolutional block (optional)\n",
        "    if hp.Boolean('include_third_conv_block'):\n",
        "        model.add(DefaultConv2D(\n",
        "            filters=hp.Int('conv_3_filter', min_value=128, max_value=512, step=128),\n",
        "            kernel_size=3))\n",
        "\n",
        "        if hp.Boolean('conv_3_second_layer'):\n",
        "            model.add(DefaultConv2D(\n",
        "                filters=hp.Int('conv_3_second_filter', min_value=128, max_value=512, step=128),\n",
        "                kernel_size=3))\n",
        "\n",
        "        model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "    # Flatten and fully connected layers\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "    # First dense layer\n",
        "    model.add(tf.keras.layers.Dense(\n",
        "        units=hp.Int('dense_1_units', min_value=64, max_value=256, step=64),\n",
        "        activation='relu',\n",
        "        kernel_initializer='he_normal'))\n",
        "\n",
        "    # Dropout rate\n",
        "    model.add(tf.keras.layers.Dropout(\n",
        "        rate=hp.Float('dropout_1', min_value=0.2, max_value=0.7, step=0.1)))\n",
        "\n",
        "    # Optional second dense layer\n",
        "    if hp.Boolean('include_second_dense'):\n",
        "        model.add(tf.keras.layers.Dense(\n",
        "            units=hp.Int('dense_2_units', min_value=32, max_value=128, step=32),\n",
        "            activation='relu',\n",
        "            kernel_initializer='he_normal'))\n",
        "        model.add(tf.keras.layers.Dropout(\n",
        "            rate=hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "class HyperModel(kt.HyperModel):\n",
        "  def build(self, hp):\n",
        "    return build_model(hp)\n",
        "\n",
        "  def fit(self, hp, model, X, y, **kwargs):\n",
        "    if hp.Boolean(\"normalize\"):\n",
        "      norm_layer = tf.keras.layers.Normalization()\n",
        "      X = norm_layer(X)\n",
        "    return model.fit(X, y, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3hIAFRosoKb"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjeNnHl34Cev"
      },
      "source": [
        "### Do Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyLUj7Lh4IGH",
        "outputId": "bf2bfc5b-0b78-42d5-fc50-74804a4d7ff8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "hyperband_tuner = kt.Hyperband(\n",
        "    HyperModel(),\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    directory=\"fashion_mnist_cnn_hyperband\",\n",
        "    project_name=\"hyperband_tuning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDITR2tR5YkH",
        "outputId": "b47a9ed2-513b-44b2-d60a-e7e19cbb5f7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 30 Complete [00h 01m 16s]\n",
            "val_accuracy: 0.9087499976158142\n",
            "\n",
            "Best val_accuracy So Far: 0.9201666712760925\n",
            "Total elapsed time: 00h 25m 18s\n"
          ]
        }
      ],
      "source": [
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True) # Interrupts training when no progress on validation set for 2 trials\n",
        "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"fashion_mnist_cnn.keras\",\n",
        "                                                         save_best_only=True) # Auto save best model\n",
        "\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb]\n",
        "\n",
        "\n",
        "hyperband_tuner.search(train_images, train_labels, epochs=15, validation_split=0.2,\n",
        "                             callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWVgK41N57NO"
      },
      "source": [
        "### Get Best Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "h31rZJih59Si"
      },
      "outputs": [],
      "source": [
        "best_hps=hyperband_tuner.get_best_hyperparameters(num_trials=1)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFoEODyjA_5G"
      },
      "source": [
        "### Find optimal number of epochs to train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfEGL709BD3X",
        "outputId": "e5b5bf8f-6b17-482c-dd52-0d07858d4d54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5538 - loss: 1.3703 - val_accuracy: 0.8165 - val_loss: 0.5044\n",
            "Epoch 2/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7953 - loss: 0.5748 - val_accuracy: 0.8485 - val_loss: 0.4113\n",
            "Epoch 3/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8384 - loss: 0.4711 - val_accuracy: 0.8630 - val_loss: 0.3832\n",
            "Epoch 4/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8699 - loss: 0.3763 - val_accuracy: 0.8640 - val_loss: 0.3706\n",
            "Epoch 5/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8799 - loss: 0.3458 - val_accuracy: 0.8760 - val_loss: 0.3592\n",
            "Epoch 6/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8966 - loss: 0.2903 - val_accuracy: 0.8785 - val_loss: 0.3469\n",
            "Epoch 7/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9197 - loss: 0.2268 - val_accuracy: 0.8705 - val_loss: 0.3803\n",
            "Epoch 8/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9171 - loss: 0.2380 - val_accuracy: 0.8860 - val_loss: 0.3427\n",
            "Epoch 9/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9347 - loss: 0.1776 - val_accuracy: 0.8945 - val_loss: 0.3200\n",
            "Epoch 10/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9336 - loss: 0.1855 - val_accuracy: 0.8890 - val_loss: 0.3552\n",
            "Epoch 11/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9498 - loss: 0.1487 - val_accuracy: 0.8810 - val_loss: 0.3615\n",
            "Epoch 12/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9559 - loss: 0.1288 - val_accuracy: 0.8880 - val_loss: 0.3910\n",
            "Epoch 13/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9594 - loss: 0.1117 - val_accuracy: 0.8985 - val_loss: 0.3437\n",
            "Epoch 14/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9658 - loss: 0.0951 - val_accuracy: 0.8925 - val_loss: 0.4148\n",
            "Epoch 15/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9702 - loss: 0.0845 - val_accuracy: 0.8895 - val_loss: 0.4237\n",
            "Epoch 16/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9726 - loss: 0.0738 - val_accuracy: 0.8935 - val_loss: 0.4200\n",
            "Epoch 17/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9739 - loss: 0.0732 - val_accuracy: 0.8995 - val_loss: 0.4304\n",
            "Epoch 18/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9806 - loss: 0.0554 - val_accuracy: 0.8950 - val_loss: 0.5028\n",
            "Epoch 19/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9843 - loss: 0.0498 - val_accuracy: 0.9010 - val_loss: 0.4666\n",
            "Epoch 20/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9877 - loss: 0.0389 - val_accuracy: 0.8900 - val_loss: 0.5241\n",
            "Epoch 21/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.0498 - val_accuracy: 0.8780 - val_loss: 0.5855\n",
            "Epoch 22/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9832 - loss: 0.0478 - val_accuracy: 0.8830 - val_loss: 0.6200\n",
            "Epoch 23/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9815 - loss: 0.0556 - val_accuracy: 0.8865 - val_loss: 0.5270\n",
            "Epoch 24/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9901 - loss: 0.0302 - val_accuracy: 0.8940 - val_loss: 0.5544\n",
            "Epoch 25/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9901 - loss: 0.0338 - val_accuracy: 0.8940 - val_loss: 0.6448\n",
            "Epoch 26/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9906 - loss: 0.0278 - val_accuracy: 0.8925 - val_loss: 0.6018\n",
            "Epoch 27/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0659 - val_accuracy: 0.8920 - val_loss: 0.5077\n",
            "Epoch 28/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9912 - loss: 0.0321 - val_accuracy: 0.8930 - val_loss: 0.5657\n",
            "Epoch 29/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0227 - val_accuracy: 0.8890 - val_loss: 0.6134\n",
            "Epoch 30/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0311 - val_accuracy: 0.8970 - val_loss: 0.6939\n",
            "Epoch 31/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.0388 - val_accuracy: 0.8965 - val_loss: 0.6645\n",
            "Epoch 32/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.0458 - val_accuracy: 0.8875 - val_loss: 0.6421\n",
            "Epoch 33/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9905 - loss: 0.0283 - val_accuracy: 0.8895 - val_loss: 0.7840\n",
            "Epoch 34/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9870 - loss: 0.0357 - val_accuracy: 0.8905 - val_loss: 0.6614\n",
            "Epoch 35/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9917 - loss: 0.0221 - val_accuracy: 0.8970 - val_loss: 0.7601\n",
            "Epoch 36/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0130 - val_accuracy: 0.8870 - val_loss: 0.8244\n",
            "Epoch 37/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.0299 - val_accuracy: 0.8810 - val_loss: 0.7194\n",
            "Epoch 38/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0150 - val_accuracy: 0.8880 - val_loss: 0.7254\n",
            "Epoch 39/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0286 - val_accuracy: 0.8860 - val_loss: 0.6980\n",
            "Epoch 40/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9930 - loss: 0.0234 - val_accuracy: 0.8910 - val_loss: 0.5730\n",
            "Epoch 41/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9941 - loss: 0.0185 - val_accuracy: 0.8915 - val_loss: 0.7853\n",
            "Epoch 42/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.0245 - val_accuracy: 0.8815 - val_loss: 0.7215\n",
            "Epoch 43/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0215 - val_accuracy: 0.8885 - val_loss: 0.7675\n",
            "Epoch 44/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9900 - loss: 0.0317 - val_accuracy: 0.8770 - val_loss: 0.8381\n",
            "Epoch 45/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0345 - val_accuracy: 0.8840 - val_loss: 0.7222\n",
            "Epoch 46/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0231 - val_accuracy: 0.8790 - val_loss: 0.7418\n",
            "Epoch 47/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9912 - loss: 0.0287 - val_accuracy: 0.8890 - val_loss: 0.8148\n",
            "Epoch 48/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0102 - val_accuracy: 0.8860 - val_loss: 0.7536\n",
            "Epoch 49/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9955 - loss: 0.0160 - val_accuracy: 0.8885 - val_loss: 0.8634\n",
            "Epoch 50/50\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.0121 - val_accuracy: 0.8910 - val_loss: 0.8180\n",
            "Best epoch: 19\n"
          ]
        }
      ],
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "finding_optimal_epochs_model = hyperband_tuner.hypermodel.build(best_hps)\n",
        "history = finding_optimal_epochs_model.fit(train_images, train_labels, epochs=50, validation_split=0.2)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXD_VmCDByOU"
      },
      "source": [
        "### Train new model with hyper-parameters on optimal number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSwOqN0pB2cO",
        "outputId": "ff27fdcc-85a1-420f-b9df-027118d8026e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7166 - loss: 0.7912 - val_accuracy: 0.8812 - val_loss: 0.3237\n",
            "Epoch 2/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8810 - loss: 0.3462 - val_accuracy: 0.8964 - val_loss: 0.2860\n",
            "Epoch 3/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9057 - loss: 0.2756 - val_accuracy: 0.9081 - val_loss: 0.2475\n",
            "Epoch 4/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9183 - loss: 0.2348 - val_accuracy: 0.9093 - val_loss: 0.2573\n",
            "Epoch 5/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9277 - loss: 0.2043 - val_accuracy: 0.9172 - val_loss: 0.2391\n",
            "Epoch 6/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9372 - loss: 0.1764 - val_accuracy: 0.9155 - val_loss: 0.2440\n",
            "Epoch 7/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9433 - loss: 0.1558 - val_accuracy: 0.9182 - val_loss: 0.2383\n",
            "Epoch 8/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9501 - loss: 0.1372 - val_accuracy: 0.9223 - val_loss: 0.2564\n",
            "Epoch 9/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9565 - loss: 0.1206 - val_accuracy: 0.9191 - val_loss: 0.2594\n",
            "Epoch 10/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9597 - loss: 0.1099 - val_accuracy: 0.9230 - val_loss: 0.2737\n",
            "Epoch 11/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9642 - loss: 0.0974 - val_accuracy: 0.9212 - val_loss: 0.2937\n",
            "Epoch 12/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9669 - loss: 0.0894 - val_accuracy: 0.9202 - val_loss: 0.2816\n",
            "Epoch 13/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9710 - loss: 0.0816 - val_accuracy: 0.9221 - val_loss: 0.2877\n",
            "Epoch 14/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9766 - loss: 0.0654 - val_accuracy: 0.9224 - val_loss: 0.3032\n",
            "Epoch 15/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9768 - loss: 0.0675 - val_accuracy: 0.9167 - val_loss: 0.3452\n",
            "Epoch 16/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9789 - loss: 0.0628 - val_accuracy: 0.9212 - val_loss: 0.3395\n",
            "Epoch 17/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.0598 - val_accuracy: 0.9200 - val_loss: 0.3738\n",
            "Epoch 18/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.0550 - val_accuracy: 0.9228 - val_loss: 0.3886\n",
            "Epoch 19/19\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9830 - loss: 0.0502 - val_accuracy: 0.9191 - val_loss: 0.3946\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b5c4e545610>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hypermodel = hyperband_tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(train_images, train_labels, epochs=best_epoch, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5h1cmHAs0fq"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg-zP68Fs1qG",
        "outputId": "6ca162c5-0c23-474d-f092-cb1b566fbaf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9149 - loss: 0.4263\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.3972543179988861, 0.9178000092506409]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hypermodel.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p0Jkl8Qwtiv"
      },
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "z1g-UbhRtS81"
      },
      "outputs": [],
      "source": [
        "hypermodel.save('fashion_mnist_cnn.keras')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
