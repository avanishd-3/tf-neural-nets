{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Trying to get over 98% accuracy on MNIST"
      ],
      "metadata": {
        "id": "qvN43qNpmO7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install keras-tuner\n",
        "%pip install tensorboard-plugin-profile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGebPixopGqx",
        "outputId": "a823155a-d815-4914-fbbd-7a24a4009583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n",
            "Collecting tensorboard-plugin-profile\n",
            "  Downloading tensorboard_plugin_profile-2.19.0-cp311-none-manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting gviz-api>=1.9.0 (from tensorboard-plugin-profile)\n",
            "  Downloading gviz_api-1.10.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: protobuf<5.0.0dev,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard-plugin-profile) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard-plugin-profile) (75.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard-plugin-profile) (1.17.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.11/dist-packages (from tensorboard-plugin-profile) (3.1.3)\n",
            "Requirement already satisfied: etils>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from etils[epath]>=1.0.0->tensorboard-plugin-profile) (1.12.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath]>=1.0.0->tensorboard-plugin-profile) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath]>=1.0.0->tensorboard-plugin-profile) (6.5.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from etils[epath]>=1.0.0->tensorboard-plugin-profile) (4.12.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath]>=1.0.0->tensorboard-plugin-profile) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=0.11.15->tensorboard-plugin-profile) (3.0.2)\n",
            "Downloading tensorboard_plugin_profile-2.19.0-cp311-none-manylinux2014_x86_64.whl (25.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gviz_api-1.10.0-py2.py3-none-any.whl (13 kB)\n",
            "Installing collected packages: gviz-api, tensorboard-plugin-profile\n",
            "Successfully installed gviz-api-1.10.0 tensorboard-plugin-profile-2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCNb1vm_mC2i"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras_tuner as kt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load MNIST dataset"
      ],
      "metadata": {
        "id": "2qOLzSmemW0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist\n",
        "\n",
        "# Scale down pixel intensities\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "print(x_train.shape) # Look at data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgXLC_zjmUYI",
        "outputId": "e074f183-842c-431b-a101-ee9782922f41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "(60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Model"
      ],
      "metadata": {
        "id": "mhREgYTfms0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_mnist_model(hp):\n",
        "    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=4, default=2)\n",
        "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=512)\n",
        "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=5e-1, sampling=\"log\")\n",
        "    optimizer = hp.Choice(\"optimizer\", values=[\"nadam\", \"adam\", \"rmsprop\"])\n",
        "\n",
        "    dropout = hp.Float(\"dropout\", min_value=0.0, max_value=0.5)\n",
        "\n",
        "    if optimizer == \"sgd\":\n",
        "      optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    else:\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "    for _ in range(n_hidden):\n",
        "      model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "      model.add(tf.keras.layers.Dropout(dropout))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "class MnistHyperModel(kt.HyperModel):\n",
        "  def build(self, hp):\n",
        "    return build_mnist_model(hp)\n",
        "\n",
        "  def fit(self, hp, model, X, y, **kwargs):\n",
        "    if hp.Boolean(\"normalize\"):\n",
        "      norm_layer = tf.keras.layers.Normalization()\n",
        "      X = norm_layer(X)\n",
        "    return model.fit(X, y, **kwargs)\n"
      ],
      "metadata": {
        "id": "qLryD8ulmsX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "qiCiKDbLnJ9p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Do Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "nLP7usV3q8I_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_hyperband_tuner = kt.Hyperband(\n",
        "    MnistHyperModel(),\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    directory=\"mnist_hyperband\",\n",
        "    project_name=\"hyperband_tuning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K65BES1nLND",
        "outputId": "e83b76a0-e218-449f-97af-ed6330de822b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_root_logdir = Path(mnist_hyperband_tuner.project_dir) / \"tensorboard\"\n",
        "mnist_tensorboard_cb = tf.keras.callbacks.TensorBoard(mnist_root_logdir) # Allows for TensorBoard visualization\n",
        "\n",
        "mnist_early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True) # Interrupts training when no progress on validation set for 2 trials\n",
        "\n",
        "mnist_hyperband_tuner.search(x_train, y_train, epochs=10, validation_split=0.2,\n",
        "                             callbacks=[mnist_early_stopping_cb, mnist_tensorboard_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXofN9moqhJN",
        "outputId": "da5014a5-01e5-456f-eeb3-fe914968b91a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 00m 34s]\n",
            "val_accuracy: 0.10616666823625565\n",
            "\n",
            "Best val_accuracy So Far: 0.9804999828338623\n",
            "Total elapsed time: 00h 13m 36s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get best hyperparameters"
      ],
      "metadata": {
        "id": "XcOlpdmKq-rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps=mnist_hyperband_tuner.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "id": "yoKK9dO6rJrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find optimal number of epochs to train"
      ],
      "metadata": {
        "id": "4pNICPCvxt0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "finding_optimal_epochs_model = mnist_hyperband_tuner.hypermodel.build(best_hps)\n",
        "history = finding_optimal_epochs_model.fit(x_train, y_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laS_yZ9fxuuT",
        "outputId": "b9e0d584-2c4b-43a8-da91-41293c6e2bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7734 - loss: 0.7357 - val_accuracy: 0.9504 - val_loss: 0.1671\n",
            "Epoch 2/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.2029 - val_accuracy: 0.9638 - val_loss: 0.1208\n",
            "Epoch 3/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9588 - loss: 0.1382 - val_accuracy: 0.9716 - val_loss: 0.0947\n",
            "Epoch 4/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.1088 - val_accuracy: 0.9732 - val_loss: 0.0884\n",
            "Epoch 5/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9741 - loss: 0.0886 - val_accuracy: 0.9751 - val_loss: 0.0840\n",
            "Epoch 6/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9764 - loss: 0.0760 - val_accuracy: 0.9763 - val_loss: 0.0771\n",
            "Epoch 7/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9799 - loss: 0.0662 - val_accuracy: 0.9788 - val_loss: 0.0761\n",
            "Epoch 8/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.0592 - val_accuracy: 0.9785 - val_loss: 0.0751\n",
            "Epoch 9/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9846 - loss: 0.0490 - val_accuracy: 0.9793 - val_loss: 0.0722\n",
            "Epoch 10/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9854 - loss: 0.0472 - val_accuracy: 0.9787 - val_loss: 0.0742\n",
            "Epoch 11/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9849 - loss: 0.0448 - val_accuracy: 0.9787 - val_loss: 0.0750\n",
            "Epoch 12/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0413 - val_accuracy: 0.9794 - val_loss: 0.0820\n",
            "Epoch 13/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.0356 - val_accuracy: 0.9794 - val_loss: 0.0772\n",
            "Epoch 14/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0324 - val_accuracy: 0.9809 - val_loss: 0.0770\n",
            "Epoch 15/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0307 - val_accuracy: 0.9808 - val_loss: 0.0731\n",
            "Epoch 16/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9902 - loss: 0.0293 - val_accuracy: 0.9796 - val_loss: 0.0804\n",
            "Epoch 17/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9904 - loss: 0.0287 - val_accuracy: 0.9812 - val_loss: 0.0772\n",
            "Epoch 18/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0230 - val_accuracy: 0.9820 - val_loss: 0.0718\n",
            "Epoch 19/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0231 - val_accuracy: 0.9810 - val_loss: 0.0788\n",
            "Epoch 20/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0216 - val_accuracy: 0.9815 - val_loss: 0.0776\n",
            "Epoch 21/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0225 - val_accuracy: 0.9820 - val_loss: 0.0775\n",
            "Epoch 22/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0218 - val_accuracy: 0.9812 - val_loss: 0.0813\n",
            "Epoch 23/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0229 - val_accuracy: 0.9805 - val_loss: 0.0849\n",
            "Epoch 24/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9939 - loss: 0.0189 - val_accuracy: 0.9819 - val_loss: 0.0824\n",
            "Epoch 25/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9933 - loss: 0.0202 - val_accuracy: 0.9823 - val_loss: 0.0794\n",
            "Epoch 26/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0220 - val_accuracy: 0.9816 - val_loss: 0.0824\n",
            "Epoch 27/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0178 - val_accuracy: 0.9822 - val_loss: 0.0805\n",
            "Epoch 28/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0166 - val_accuracy: 0.9828 - val_loss: 0.0856\n",
            "Epoch 29/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0187 - val_accuracy: 0.9832 - val_loss: 0.0830\n",
            "Epoch 30/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0171 - val_accuracy: 0.9815 - val_loss: 0.0852\n",
            "Epoch 31/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0169 - val_accuracy: 0.9842 - val_loss: 0.0777\n",
            "Epoch 32/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0144 - val_accuracy: 0.9819 - val_loss: 0.0940\n",
            "Epoch 33/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0165 - val_accuracy: 0.9828 - val_loss: 0.0838\n",
            "Epoch 34/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0139 - val_accuracy: 0.9824 - val_loss: 0.0894\n",
            "Epoch 35/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0142 - val_accuracy: 0.9827 - val_loss: 0.0899\n",
            "Epoch 36/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0126 - val_accuracy: 0.9821 - val_loss: 0.0916\n",
            "Epoch 37/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0122 - val_accuracy: 0.9822 - val_loss: 0.0907\n",
            "Epoch 38/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0138 - val_accuracy: 0.9831 - val_loss: 0.0859\n",
            "Epoch 39/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0147 - val_accuracy: 0.9827 - val_loss: 0.0921\n",
            "Epoch 40/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0144 - val_accuracy: 0.9832 - val_loss: 0.0872\n",
            "Epoch 41/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0133 - val_accuracy: 0.9835 - val_loss: 0.0889\n",
            "Epoch 42/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0159 - val_accuracy: 0.9827 - val_loss: 0.0938\n",
            "Epoch 43/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0138 - val_accuracy: 0.9833 - val_loss: 0.0923\n",
            "Epoch 44/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0133 - val_accuracy: 0.9843 - val_loss: 0.0875\n",
            "Epoch 45/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0128 - val_accuracy: 0.9820 - val_loss: 0.0988\n",
            "Epoch 46/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0143 - val_accuracy: 0.9828 - val_loss: 0.1011\n",
            "Epoch 47/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0097 - val_accuracy: 0.9831 - val_loss: 0.0944\n",
            "Epoch 48/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0126 - val_accuracy: 0.9841 - val_loss: 0.0917\n",
            "Epoch 49/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0115 - val_accuracy: 0.9831 - val_loss: 0.0967\n",
            "Epoch 50/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0099 - val_accuracy: 0.9835 - val_loss: 0.0937\n",
            "Best epoch: 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train new model with hyper-parameters on optimal number of epochs"
      ],
      "metadata": {
        "id": "a-2mLLHOyQtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel = mnist_hyperband_tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(x_train, y_train, epochs=best_epoch, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkezdswTyS9W",
        "outputId": "b8011c53-8968-413d-d87b-bbc41361b660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7767 - loss: 0.7222 - val_accuracy: 0.9534 - val_loss: 0.1595\n",
            "Epoch 2/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9423 - loss: 0.1964 - val_accuracy: 0.9653 - val_loss: 0.1156\n",
            "Epoch 3/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9561 - loss: 0.1452 - val_accuracy: 0.9716 - val_loss: 0.0951\n",
            "Epoch 4/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9669 - loss: 0.1107 - val_accuracy: 0.9723 - val_loss: 0.0919\n",
            "Epoch 5/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9721 - loss: 0.0885 - val_accuracy: 0.9766 - val_loss: 0.0783\n",
            "Epoch 6/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9759 - loss: 0.0752 - val_accuracy: 0.9768 - val_loss: 0.0783\n",
            "Epoch 7/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.0627 - val_accuracy: 0.9789 - val_loss: 0.0712\n",
            "Epoch 8/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9805 - loss: 0.0591 - val_accuracy: 0.9781 - val_loss: 0.0759\n",
            "Epoch 9/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9815 - loss: 0.0562 - val_accuracy: 0.9793 - val_loss: 0.0707\n",
            "Epoch 10/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9860 - loss: 0.0424 - val_accuracy: 0.9801 - val_loss: 0.0706\n",
            "Epoch 11/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9859 - loss: 0.0416 - val_accuracy: 0.9801 - val_loss: 0.0709\n",
            "Epoch 12/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.0403 - val_accuracy: 0.9818 - val_loss: 0.0690\n",
            "Epoch 13/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9882 - loss: 0.0357 - val_accuracy: 0.9808 - val_loss: 0.0701\n",
            "Epoch 14/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.0333 - val_accuracy: 0.9803 - val_loss: 0.0717\n",
            "Epoch 15/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9907 - loss: 0.0285 - val_accuracy: 0.9818 - val_loss: 0.0724\n",
            "Epoch 16/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0285 - val_accuracy: 0.9803 - val_loss: 0.0786\n",
            "Epoch 17/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9894 - loss: 0.0306 - val_accuracy: 0.9817 - val_loss: 0.0752\n",
            "Epoch 18/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0261 - val_accuracy: 0.9814 - val_loss: 0.0743\n",
            "Epoch 19/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0250 - val_accuracy: 0.9827 - val_loss: 0.0713\n",
            "Epoch 20/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0232 - val_accuracy: 0.9822 - val_loss: 0.0725\n",
            "Epoch 21/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0231 - val_accuracy: 0.9822 - val_loss: 0.0788\n",
            "Epoch 22/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0209 - val_accuracy: 0.9819 - val_loss: 0.0798\n",
            "Epoch 23/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0203 - val_accuracy: 0.9827 - val_loss: 0.0771\n",
            "Epoch 24/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0216 - val_accuracy: 0.9822 - val_loss: 0.0788\n",
            "Epoch 25/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0171 - val_accuracy: 0.9812 - val_loss: 0.0842\n",
            "Epoch 26/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0203 - val_accuracy: 0.9833 - val_loss: 0.0769\n",
            "Epoch 27/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0177 - val_accuracy: 0.9832 - val_loss: 0.0789\n",
            "Epoch 28/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0178 - val_accuracy: 0.9833 - val_loss: 0.0785\n",
            "Epoch 29/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0152 - val_accuracy: 0.9833 - val_loss: 0.0809\n",
            "Epoch 30/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0162 - val_accuracy: 0.9822 - val_loss: 0.0830\n",
            "Epoch 31/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0174 - val_accuracy: 0.9819 - val_loss: 0.0935\n",
            "Epoch 32/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0175 - val_accuracy: 0.9815 - val_loss: 0.0879\n",
            "Epoch 33/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0143 - val_accuracy: 0.9826 - val_loss: 0.0920\n",
            "Epoch 34/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0171 - val_accuracy: 0.9828 - val_loss: 0.0891\n",
            "Epoch 35/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9950 - loss: 0.0145 - val_accuracy: 0.9820 - val_loss: 0.0893\n",
            "Epoch 36/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0141 - val_accuracy: 0.9823 - val_loss: 0.0901\n",
            "Epoch 37/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0143 - val_accuracy: 0.9821 - val_loss: 0.0926\n",
            "Epoch 38/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0149 - val_accuracy: 0.9817 - val_loss: 0.0947\n",
            "Epoch 39/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0118 - val_accuracy: 0.9827 - val_loss: 0.0886\n",
            "Epoch 40/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0139 - val_accuracy: 0.9814 - val_loss: 0.0998\n",
            "Epoch 41/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0121 - val_accuracy: 0.9830 - val_loss: 0.0943\n",
            "Epoch 42/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0125 - val_accuracy: 0.9834 - val_loss: 0.0911\n",
            "Epoch 43/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0133 - val_accuracy: 0.9834 - val_loss: 0.0910\n",
            "Epoch 44/44\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0133 - val_accuracy: 0.9832 - val_loss: 0.0942\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7df710729590>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate model"
      ],
      "metadata": {
        "id": "TZfLnvWEoB13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuvJI4fvoC39",
        "outputId": "11745474-7a5f-4cec-e37a-90ed7e257133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9809 - loss: 0.1023\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08391046524047852, 0.9843999743461609]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "Sckpdd4boGC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel.save('mnist_high_accuracy_model.keras')"
      ],
      "metadata": {
        "id": "AtwtbH6AoHNN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}