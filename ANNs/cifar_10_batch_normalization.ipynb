{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Improving Neural Net accuracy with Batch Normalization"
      ],
      "metadata": {
        "id": "vJzO4EeTaw1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2okfmaugnGuC",
        "outputId": "1dda8690-69cd-4fda-c2af-959f38656fda"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p-kC8IZXamjH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras_tuner as kt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load CIFARS 10 dataset"
      ],
      "metadata": {
        "id": "ns2qWXAXa1qV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar\n",
        "\n",
        "# Scale down pixel intensities\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "print(x_train.shape) # Look at data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiPCRozWav_k",
        "outputId": "c2d8704c-9e8d-47a3-ae13-0f982ab943e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
            "(50000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Initial Model"
      ],
      "metadata": {
        "id": "PLVQyIO7bhyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=20, default=2)\n",
        "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=512)\n",
        "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=5e-1, sampling=\"log\")\n",
        "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\", \"nadam\"])\n",
        "\n",
        "    if optimizer == \"sgd\":\n",
        "      optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    elif optimizer == \"adam\":\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    else:\n",
        "      optimizer = tf.keras.optimizers.Nadam(learning_rate=learning_rate)\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=(32, 32, 3)))\n",
        "\n",
        "    for _ in range(n_hidden):\n",
        "      model.add(tf.keras.layers.Dense(n_neurons, use_bias=False))\n",
        "      model.add(tf.keras.layers.BatchNormalization()) # Use batch normalization in model (activation function after normalizatiom\n",
        "      model.add(tf.keras.layers.Activation(\"swish\"))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "class HyperModel(kt.HyperModel):\n",
        "  def build(self, hp):\n",
        "    return build_model(hp)\n",
        "\n",
        "  def fit(self, hp, model, X, y, **kwargs):\n",
        "    if hp.Boolean(\"normalize\"):\n",
        "      norm_layer = tf.keras.layers.Normalization()\n",
        "      X = norm_layer(X)\n",
        "    return model.fit(X, y, **kwargs)"
      ],
      "metadata": {
        "id": "8gLKRAAObfqJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "0nGfN15HcsY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Do Hyperparameter tuning"
      ],
      "metadata": {
        "id": "hVUVQq-OmoVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperband_tuner = kt.Hyperband(\n",
        "    HyperModel(),\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    directory=\"cifar_10_hyperband\",\n",
        "    project_name=\"hyperband_tuning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15k1Hj5pmu6D",
        "outputId": "0b31a4f7-d1e9-44a6-bc18-7210ed21699d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True) # Interrupts training when no progress on validation set for 2 trials\n",
        "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"cifar10_model.keras\",\n",
        "                                                         save_best_only=True) # Auto save best model\n",
        "\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb]\n",
        "\n",
        "\n",
        "hyperband_tuner.search(x_train, y_train, epochs=10, validation_split=0.2,\n",
        "                             callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZBlcuvIctf2",
        "outputId": "e20eab1d-a11d-477f-d2a5-662ebdc3acc9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 01m 19s]\n",
            "val_accuracy: 0.4659999907016754\n",
            "\n",
            "Best val_accuracy So Far: 0.4975000023841858\n",
            "Total elapsed time: 00h 20m 48s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get best model"
      ],
      "metadata": {
        "id": "IjRebUPHtF78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_3_models = hyperband_tuner.get_best_models(num_models=3)\n",
        "best_model = top_3_models[0]\n",
        "\n",
        "best_trial = hyperband_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
        "best_trial.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3mdUvPetHr-",
        "outputId": "6163412d-cce2-4822-a8fe-2d938b542353"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0025 summary\n",
            "Hyperparameters:\n",
            "n_hidden: 12\n",
            "n_neurons: 379\n",
            "learning_rate: 0.0007097566850047709\n",
            "optimizer: nadam\n",
            "normalize: True\n",
            "tuner/epochs: 10\n",
            "tuner/initial_epoch: 4\n",
            "tuner/bracket: 1\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0021\n",
            "Score: 0.4975000023841858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Model"
      ],
      "metadata": {
        "id": "0X19ppnMd6-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dByq9bpZd8aX",
        "outputId": "d2eaee9d-fd30-4712-b8df-9454646e977e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4903 - loss: 1.4387\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4377515316009521, 0.492000013589859]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}